{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Assginment 2: Tweets Analysis\n",
    "\n",
    "** In this assignment, you will learn: **\n",
    "* Parse Tweets from josn file\n",
    "* Collect tweets from Spark SQL and DataFrames\n",
    "* Sample tweets and call Waston API to do analysis\n",
    "* Virtualize the results\n",
    "-----\n",
    "<font color='red'>IMPORTANT: </font>This notebook contains credential information, which should be private and confidential. Plase only use it for assignment. Do not share with others and out of course life cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: Parse Tweets from josn file\n",
    "\n",
    "When crawled tweets from twitter, all the tweets information are stored in json format. SparkSQL can parse json file and transform into data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, StringIO,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'object_storage_9de0bf59_5fe2_4f11_8d80_ac12b45f3fca',\n",
    "  'project_id':'3fd339f1bd7b4ff4a1eb8da7659e39ba',\n",
    "  'region':'dallas',\n",
    "  'user_id':'46476b565b864525a6a365d41fe7a280',\n",
    "  'domain_id':'29cedac5a5ca492c83b9c6f324f7229d',\n",
    "  'domain_name':'913169',\n",
    "  'username':'Admin_28154f3d777dc89d3deb5a8285de9513c30049b3',\n",
    "  'password':\"\"\"HQ.7BPLU5W1=5Yob\"\"\",\n",
    "  'container':'notebooks',\n",
    "  'tenantId':''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_hadoop_config(credentials):\n",
    "    prefix = \"fs.swift.service.\" + credentials['name'] \n",
    "    hconf = sc._jsc.hadoopConfiguration()\n",
    "    hconf.set(prefix + \".auth.url\", credentials['auth_url']+'/v3/auth/tokens')\n",
    "    hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n",
    "    hconf.set(prefix + \".tenant\", credentials['project_id'])\n",
    "    hconf.set(prefix + \".username\", credentials['user_id'])\n",
    "    hconf.set(prefix + \".password\", credentials['password'])\n",
    "    hconf.setInt(prefix + \".http.port\", 8080)\n",
    "    hconf.set(prefix + \".region\", credentials['region'])\n",
    "    hconf.setBoolean(prefix + \".public\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials['name'] = 'keystone'\n",
    "set_hadoop_config(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = sqlContext.read.json(\"swift://notebooks.keystone/Tweets.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will do some simple text cleaning, including removing symbols, trimming and lowering the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, col, lower\n",
    "def removePunctuation(column):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        column (Column): A Column containing a sentence.\n",
    "\n",
    "    Returns:\n",
    "        Column: A Column named 'sentence' with clean-up operations applied.\n",
    "    \"\"\"\n",
    "    return regexp_replace(trim(lower(column)),'[^a-z0-9 ]','').alias('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After text cleaning, we can show some result using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_text = tweets.select(removePunctuation(col('text')))\n",
    "tweet_text.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colloect tweets from Spark SQL and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect the SQL result from Spark to local and do further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = tweet_text.sample(False,0.1).collect()\n",
    "texts = [i[0] for i in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the texts, all texts are stored in the Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Wastion Tone Analyzer API to do text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use API, we need to install it. For **Tone Analyzer** API reference, click [Here](http://www.ibm.com/watson/developercloud/doc/tone-analyzer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install watson-developer-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import ToneAnalyzerV3\n",
    "\n",
    "def tone(te):\n",
    "    tone_analyzer = ToneAnalyzerV3(\n",
    "        password =  \"FwdYI5O0TaGY\",\n",
    "        username =  \"be8de89c-f720-43eb-beec-9f52093bdb6a\",\n",
    "        version ='2016-05-19')\n",
    "    try:\n",
    "        toneresult = tone_analyzer.tone(text=te)['document_tone']['tone_categories']\n",
    "        print \"API success\"\n",
    "        return toneresult\n",
    "    except:\n",
    "        print \"API calls reaches limitation, place try again later\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = tone('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the necessary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotion_tone = dict([(i.values()[0],i.values()[1]) for i in result[0]['tones']])\n",
    "social_tone = dict([(i.values()[0],i.values()[1]) for i in result[2]['tones']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.barh(range(len(emotion_tone)),emotion_tone.values(),align='center',alpha=0.5,color='g')\n",
    "plt.yticks(range(len(emotion_tone)),emotion_tone.keys())\n",
    "plt.title('Emotion Tone')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.barh(range(len(social_tone)),social_tone.values(),align='center',alpha=0.5,color='b')\n",
    "plt.yticks(range(len(social_tone)),social_tone.keys())\n",
    "\n",
    "plt.title('Social Tone')\n",
    "for i, v in enumerate(social_tone.values()):\n",
    "    plt.text(v/2, i-0.1, str(v), color='w')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Assignment\n",
    "Copyright &copy; 2016 by Tianyang Zhang"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
